{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFO ABOUT DATASET  \n",
    "* ``` source of the data ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dementia type</th>\n",
       "      <th>birth</th>\n",
       "      <th>death</th>\n",
       "      <th>first symptoms</th>\n",
       "      <th>URLs after symptoms</th>\n",
       "      <th>5 years</th>\n",
       "      <th>5 &lt; 10 years</th>\n",
       "      <th>10 &lt; 15 years</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>datasplit</th>\n",
       "      <th>language</th>\n",
       "      <th>unknown 1</th>\n",
       "      <th>unkown 2</th>\n",
       "      <th>unknown 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abe Burrows</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1910</td>\n",
       "      <td>1985</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=VezbsmCriw4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aileen Hernandez</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1926</td>\n",
       "      <td>2017</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>https://youtu.be/x7hujcEhQuY</td>\n",
       "      <td>https://youtu.be/CshhDl-YwkY \\nhttps://youtu.b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Ramsey</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1938</td>\n",
       "      <td>2020</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=CHeXE4c6EDI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allan Burns</td>\n",
       "      <td>Lewy body</td>\n",
       "      <td>1935</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=aD3hL-kWoPc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrew Sachs</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1930</td>\n",
       "      <td>2016</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/FSgKLooW1LM</td>\n",
       "      <td>https://youtu.be/3V1iFmavqG4</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Trevor Peacock</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1931</td>\n",
       "      <td>2021</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=ktgeU7TkltA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Unita Blackwell</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1933</td>\n",
       "      <td>2019</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/gkQCvBBYkfY</td>\n",
       "      <td>female</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Vampiro</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1967</td>\n",
       "      <td>present</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>https://www.youtube.com/watch?v=Z_Mwg_Tw0rQ</td>\n",
       "      <td>https://www.youtube.com/watch?v=PnjSYL6tihs ,h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Viv Nicholson</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>1936</td>\n",
       "      <td>2015</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=254FRMcTHyU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>valid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Woody Durham</td>\n",
       "      <td>Primary progressive aphasia</td>\n",
       "      <td>1941</td>\n",
       "      <td>2018</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>https://youtu.be/H6kKf9cP_nM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian/White</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                dementia type  birth    death  \\\n",
       "0        Abe Burrows                    Alzheimer   1910     1985   \n",
       "1   Aileen Hernandez                     Dementia   1926     2017   \n",
       "2        Alan Ramsey                     Dementia   1938     2020   \n",
       "3        Allan Burns                    Lewy body   1935     2021   \n",
       "4       Andrew Sachs                     Dementia   1930     2016   \n",
       "..               ...                          ...    ...      ...   \n",
       "79    Trevor Peacock                    Alzheimer   1931     2021   \n",
       "80   Unita Blackwell                     Dementia   1933     2019   \n",
       "81           Vampiro                    Alzheimer   1967  present   \n",
       "82     Viv Nicholson                     Dementia   1936     2015   \n",
       "83      Woody Durham  Primary progressive aphasia   1941     2018   \n",
       "\n",
       "    first symptoms                          URLs after symptoms  \\\n",
       "0           1975.0                                          NaN   \n",
       "1           2012.0                 https://youtu.be/x7hujcEhQuY   \n",
       "2           2015.0                                          NaN   \n",
       "3              NaN                                          NaN   \n",
       "4           2012.0                                          NaN   \n",
       "..             ...                                          ...   \n",
       "79          2016.0                                          NaN   \n",
       "80          2008.0                                          NaN   \n",
       "81          2019.0  https://www.youtube.com/watch?v=Z_Mwg_Tw0rQ   \n",
       "82          2010.0                                          NaN   \n",
       "83          2008.0                 https://youtu.be/H6kKf9cP_nM   \n",
       "\n",
       "                                              5 years  \\\n",
       "0         https://www.youtube.com/watch?v=VezbsmCriw4   \n",
       "1   https://youtu.be/CshhDl-YwkY \\nhttps://youtu.b...   \n",
       "2         https://www.youtube.com/watch?v=CHeXE4c6EDI   \n",
       "3         https://www.youtube.com/watch?v=aD3hL-kWoPc   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "79        https://www.youtube.com/watch?v=ktgeU7TkltA   \n",
       "80                                                NaN   \n",
       "81  https://www.youtube.com/watch?v=PnjSYL6tihs ,h...   \n",
       "82        https://www.youtube.com/watch?v=254FRMcTHyU   \n",
       "83                                                NaN   \n",
       "\n",
       "                    5 < 10 years                 10 < 15 years  gender  \\\n",
       "0                            NaN                           NaN    male   \n",
       "1                            NaN                           NaN  female   \n",
       "2                            NaN                           NaN    male   \n",
       "3                            NaN                           NaN    male   \n",
       "4   https://youtu.be/FSgKLooW1LM  https://youtu.be/3V1iFmavqG4    male   \n",
       "..                           ...                           ...     ...   \n",
       "79                           NaN                           NaN    male   \n",
       "80                           NaN  https://youtu.be/gkQCvBBYkfY  female   \n",
       "81                           NaN                           NaN    male   \n",
       "82                           NaN                           NaN  female   \n",
       "83                           NaN                           NaN    male   \n",
       "\n",
       "                 ethnicity datasplit  language unknown 1  unkown 2  unknown 3  \n",
       "0          Caucasian/White     train       NaN       NaN       NaN        NaN  \n",
       "1   Black/African American     train       NaN       NaN       NaN        NaN  \n",
       "2          Caucasian/White     train       NaN       NaN       NaN        NaN  \n",
       "3          Caucasian/White     train       NaN       NaN       NaN        NaN  \n",
       "4                      NaN     train       NaN       NaN       NaN        NaN  \n",
       "..                     ...       ...       ...       ...       ...        ...  \n",
       "79         Caucasian/White     train       NaN       NaN       NaN        NaN  \n",
       "80  Black/African American     train       NaN       NaN       NaN        NaN  \n",
       "81         Caucasian/White      test       NaN       NaN       NaN        NaN  \n",
       "82         Caucasian/White     valid       NaN       NaN       NaN        NaN  \n",
       "83         Caucasian/White     train       NaN       NaN       NaN        NaN  \n",
       "\n",
       "[84 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df = pd.read_csv('data/DementiaNet.csv' , header = 'infer')\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   name                 84 non-null     object \n",
      " 1   dementia type        84 non-null     object \n",
      " 2   birth                84 non-null     int64  \n",
      " 3   death                82 non-null     object \n",
      " 4   first symptoms       79 non-null     float64\n",
      " 5   URLs after symptoms  29 non-null     object \n",
      " 6   5 years              39 non-null     object \n",
      " 7   5 < 10 years         36 non-null     object \n",
      " 8   10 < 15 years        26 non-null     object \n",
      " 9   gender               83 non-null     object \n",
      " 10  ethnicity            83 non-null     object \n",
      " 11  datasplit            84 non-null     object \n",
      " 12  language             0 non-null      float64\n",
      " 13  unknown 1            2 non-null      object \n",
      " 14  unkown 2             0 non-null      float64\n",
      " 15  unknown 3            0 non-null      float64\n",
      "dtypes: float64(4), int64(1), object(11)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "info_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Collected dataset stred with their path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daningram_15</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Dan Ingram/daningram_15.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terryjones_5</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Terry Jones/terryjones_5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maureenforrester_5</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Maureen Forrester/maureenforrest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aileenhernandez_0</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Aileen Hernandez/aileenhernandez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aileenhernandez_5_1</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Aileen Hernandez/aileenhernandez...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file     label  \\\n",
       "0         daningram_15  dementia   \n",
       "1         terryjones_5  dementia   \n",
       "2   maureenforrester_5  dementia   \n",
       "3    aileenhernandez_0  dementia   \n",
       "4  aileenhernandez_5_1  dementia   \n",
       "\n",
       "                                                path  \n",
       "0          data/dementia/Dan Ingram/daningram_15.wav  \n",
       "1         data/dementia/Terry Jones/terryjones_5.wav  \n",
       "2  data/dementia/Maureen Forrester/maureenforrest...  \n",
       "3  data/dementia/Aileen Hernandez/aileenhernandez...  \n",
       "4  data/dementia/Aileen Hernandez/aileenhernandez...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train_dm.csv' , header='infer')\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JimmyCalderwood_5</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Jimmy Calderwood/JimmyCalderwood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vivnicholson_5</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Viv Nicholson/vivnicholson_5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IanHolm_2</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Ian Holm/IanHolm_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CharmianCarr_15</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Charmian Carr/CharmianCarr_15.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CharmianCarr_5</td>\n",
       "      <td>dementia</td>\n",
       "      <td>data/dementia/Charmian Carr/CharmianCarr_5.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file     label  \\\n",
       "0  JimmyCalderwood_5  dementia   \n",
       "1     vivnicholson_5  dementia   \n",
       "2          IanHolm_2  dementia   \n",
       "3    CharmianCarr_15  dementia   \n",
       "4     CharmianCarr_5  dementia   \n",
       "\n",
       "                                                path  \n",
       "0  data/dementia/Jimmy Calderwood/JimmyCalderwood...  \n",
       "1     data/dementia/Viv Nicholson/vivnicholson_5.wav  \n",
       "2               data/dementia/Ian Holm/IanHolm_2.wav  \n",
       "3    data/dementia/Charmian Carr/CharmianCarr_15.wav  \n",
       "4     data/dementia/Charmian Carr/CharmianCarr_5.wav  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv('data/valid_dm.csv' , header='infer')\n",
    "valid_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class distriburion of the dataset \n",
    "*  class1 : ```dementia...```\n",
    "*  class0 : ```no-dementia```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dementia</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodementia</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            path\n",
       "label           \n",
       "dementia     106\n",
       "nodementia   121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('label').count()[['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dementia</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodementia</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            path\n",
       "label           \n",
       "dementia      20\n",
       "nodementia    28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby('label').count()[['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 8114478 bytes\n",
      "Last modified: 1725041597.110077\n",
      "Last accessed: 1725048187.5094182\n",
      "Created: 315513000.0\n",
      "Mode: 33206\n",
      "Owner User ID: 0\n",
      "Owner Group ID: 0\n",
      "daningram_15.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = train_df['path'][0]\n",
    "# the csv is used to extract info and attach label to file\n",
    "if os.path.isfile(file_path):\n",
    "    file_info = os.stat(file_path)\n",
    "    print(f\"Size: {file_info.st_size} bytes\")\n",
    "    print(f\"Last modified: {file_info.st_mtime}\")\n",
    "    print(f\"Last accessed: {file_info.st_atime}\")\n",
    "    print(f\"Created: {file_info.st_ctime}\")\n",
    "    print(f\"Mode: {file_info.st_mode}\")\n",
    "    print(f\"Owner User ID: {file_info.st_uid}\")\n",
    "    print(f\"Owner Group ID: {file_info.st_gid}\")\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(file_name)  # Output: file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Py-Torch text extraction from audio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Loading the Model and Tokenizer**:\n",
    "   - We load the pre-trained Wav2Vec 2.0 model (`Wav2Vec2ForCTC`) and its corresponding tokenizer (`Wav2Vec2Tokenizer`) from the Hugging Face `transformers` library.\n",
    "   - The model used in this example is `facebook/wav2vec2-base-960h`, which is trained on 960 hours of English speech.\n",
    "\n",
    "2. **Loading and Resampling Audio**:\n",
    "   - We use `torchaudio` to load the audio file. The audio is read into the `speech` variable, and its sample rate is stored in `sample_rate`.\n",
    "   - If the sample rate of the audio is not 16 kHz, we resample it using `torchaudio.transforms.Resample` to match the model's requirement.\n",
    "\n",
    "3. **Tokenization**:\n",
    "   - The audio waveform is tokenized into input values using the `tokenizer`. These input values are in a format that the model can process.\n",
    "   - The `squeeze()` function is used to remove any extra dimensions from the tensor, and `return_tensors=\"pt\"` ensures that the input is returned as a PyTorch tensor.\n",
    "\n",
    "4. **Inference**:\n",
    "   - The input values are passed through the model using `model(input_values)`. The model returns logits, which are raw, unnormalized scores for each possible output class (in this case, each character in the transcription).\n",
    "   - We use `torch.no_grad()` to disable gradient calculations, which reduces memory usage and speeds up inference since we are not training the model.\n",
    "\n",
    "5. **Decoding**:\n",
    "   - The logits are converted into predicted IDs by finding the indices of the highest probability values using `torch.argmax(logits, dim=-1)`.\n",
    "   - Finally, the predicted IDs are decoded into the transcription (text) using the `tokenizer.decode()` function.\n",
    "\n",
    "6. **Output**:\n",
    "   - The transcription is printed out, which is the text representation of the spoken words in the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sashr\\AppData\\Local\\Temp\\ipykernel_42552\\2189625076.py:4: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "torchaudio.set_audio_backend(\"sox_io\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading facebook pre trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "c:\\Users\\sashr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sashr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dementia/Dan Ingram/daningram_15.wav\n"
     ]
    }
   ],
   "source": [
    "print(train_df['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG BEFORE THE BLACK YET BLACKOUT BLACKOUT WAS SUDDENLY EVERYTHIN INSTORED INTO SLOW DRIN THOSE DAYS THAT TAKE MACHINES WERE HOOKED UP TO SIXTY CYCLE CURRENT AND WHEN THE CURRENT STARTED GOING DOWN THEY STARTE ON DOWN TRUE FIVE TWENTY SEVEN IN THE MIDDLE OF HE NEWSCAST POO AND WERE GONE THAT WAS IT THAT HE GAVE ME AN ARMLOAD OF ELL PEES AND SAID GET IN THE CAR BECAUSE THE ONLY PLACE IN THE YORK CITY THAT HAD POWER WAS LOADI NEW JERSEY WHERE WE HAD OUR TRANSMITTE RIGHT SO WE WERE ON HERE AND I WAS ON ERTO FOUR THIRTY IN THE MORNING DOING MY FIRST TALKSHILL I INVENTED TALKED RADIO AND OTOS TI JUNLY DI HAVE A TURN TAVY I GOT OT ARM LOAD OF RECORDS AND NO TURN TO AND I WAS BROUGHT GASZING OUT OF THE TRAN\n"
     ]
    }
   ],
   "source": [
    "speech, sample_rate = torchaudio.load(train_df['path'][0])\n",
    "\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    speech = resampler(speech)\n",
    "\n",
    "input_values = tokenizer(speech.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.decode(predicted_ids[0])\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(path):\n",
    "   speech, sample_rate = torchaudio.load(path)\n",
    "   if sample_rate != 16000:\n",
    "      resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "      speech = resampler(speech)\n",
    "   input_values = tokenizer(speech.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
    "   with torch.no_grad():\n",
    "      logits = model(input_values).logits\n",
    "   predicted_ids = torch.argmax(logits, dim=-1)\n",
    "   transcription = tokenizer.decode(predicted_ids[0])\n",
    "   return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LONG BEFORE THE BLACK YET BLACKOUT BLACKOUT WAS SUDDENLY EVERYTHIN INSTORED INTO SLOW DRIN THOSE DAYS THAT TAKE MACHINES WERE HOOKED UP TO SIXTY CYCLE CURRENT AND WHEN THE CURRENT STARTED GOING DOWN THEY STARTE ON DOWN TRUE FIVE TWENTY SEVEN IN THE MIDDLE OF HE NEWSCAST POO AND WERE GONE THAT WAS IT THAT HE GAVE ME AN ARMLOAD OF ELL PEES AND SAID GET IN THE CAR BECAUSE THE ONLY PLACE IN THE YORK CITY THAT HAD POWER WAS LOADI NEW JERSEY WHERE WE HAD OUR TRANSMITTE RIGHT SO WE WERE ON HERE AND I WAS ON ERTO FOUR THIRTY IN THE MORNING DOING MY FIRST TALKSHILL I INVENTED TALKED RADIO AND OTOS TI JUNLY DI HAVE A TURN TAVY I GOT OT ARM LOAD OF RECORDS AND NO TURN TO AND I WAS BROUGHT GASZING OUT OF THE TRAN'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_audio(train_df['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making csv data of trancritpt and the class dementia \n",
    "\n",
    "# train_df['transcription'] = train_df['path'].apply(lambda x: transcribe_audio(x))\n",
    "# valid_df['transcription'] = valid_df['path'].apply(lambda x: transcribe_audio(x))\n",
    "\n",
    "# train_df.to_csv('data/train_dm_transcription.csv', index=False)\n",
    "# valid_df.to_csv('data/valid_dm_transcription.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE : due to time intensive work using assembli ai api for conversion \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "# Replace with your API key\n",
    "aai.settings.api_key = \"687063c7417345c4b8de68a676b60714\"\n",
    "transcriber = aai.Transcriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(FILE_URL):\n",
    "   transcript = transcriber.transcribe(FILE_URL)\n",
    "   return transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Long before the blackout. All right, yeah. Blackout. Blackout was suddenly everything started to slow down, because in those days, the tape machines were hooked up to 60 cycle current. And when the current started going down, they started going down. True. And at 527, in the middle of a newscast, poof. And we're gone. That was it. They gave me an armload of LP's and said, get in the car. Because the only place in New York City that had power was Lodi, New Jersey, where we had our transmitter, right? So we were on the air, and I was on the air till 430 in the morning doing my first talk show. I invented talk radio and nothing else to do. We didn't have a turntable. I got an armload of records and no turntable, and I was broadcasting out of the transde.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_audio(train_df['path'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meathedology for Audio and Text binary classification <br>\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Classification</th>\n",
    "      <th>Extension</th>\n",
    "      <th>Representation</th>\n",
    "      <th>Model</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Text</td>\n",
    "      <td>.txt</td>\n",
    "      <td>Transcript</td>\n",
    "      <td>Sequential</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Audio</td>\n",
    "      <td>.wav</td>\n",
    "      <td>Dense Vector</td>\n",
    "      <td>Transformer</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
